{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from random import shuffle\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "# from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_list(*ls):\n",
    "  l =list(zip(*ls))\n",
    "\n",
    "  shuffle(l)\n",
    "  return zip(*l)\n",
    "\n",
    "def df2dict(panda_data, gpt_data, gpt_type=False, both_labels=False):\n",
    "    text = []\n",
    "    labels = []\n",
    "    \n",
    "    if (gpt_type) != False:\n",
    "        gpt_data = gpt_data[gpt_data['SAMPLE_TYPE'].isin(gpt_type)]\n",
    "        gpt_data = gpt_data.to_numpy()\n",
    "        for i in range(len(gpt_data)):\n",
    "            text.append(gpt_data[i][1])\n",
    "            labels.append('__label1__')\n",
    "\n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    # both real and fake data in amazon\n",
    "    if both_labels == True:\n",
    "        for i in range(len(np_data)):\n",
    "            text.append(np_data[i][8])\n",
    "            labels.append(np_data[i][1])\n",
    "\n",
    "    # real data only in amazon\n",
    "    else:\n",
    "        for i in range(len(np_data)):\n",
    "            if np_data[i][1] == '__label2__':\n",
    "                text.append(np_data[i][8])\n",
    "                labels.append(np_data[i][1])\n",
    "    \n",
    "    text, labels = shuffle_list(text,labels)\n",
    "\n",
    "    data_dict = {'text': text,\n",
    "                'labels': labels} \n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_extraction with sklearn methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(n_range, info):\n",
    "    print(info)\n",
    "    best_acc = 0\n",
    "    for clf, name in (\n",
    "            # (LinearSVC(), \"LinearSVC\"),\n",
    "            (MultinomialNB(), \"Multi  NB\"),\n",
    "            (RidgeClassifier(), \"Ridge cls\"),\n",
    "            (SGDClassifier(), \"SGD   cls\"),\n",
    "            # the following 3 preform quite bad\n",
    "            # (PassiveAggressiveClassifier(), \"Pass-Aggr\"),\n",
    "            # (Perceptron(), \"Perceptro\"),\n",
    "            # (KNeighborsClassifier(), \"k - N - N\"),\n",
    "            ):\n",
    "\n",
    "        text_clf = Pipeline([\n",
    "                            ('vect', CountVectorizer(ngram_range=n_range)),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', clf),\n",
    "                            ])\n",
    "\n",
    "        text_clf.fit(train_data['text'], train_data['labels'])\n",
    "\n",
    "        predicted = text_clf.predict(test_data['text'])\n",
    "        acc = np.mean(predicted == test_data['labels'])\n",
    "\n",
    "        print(name, acc)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_result = (name, acc)\n",
    "    \n",
    "    print('Best result in this run: ', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original pd dataframe 15750 5250\n",
      "processed data 15750 5250\n",
      "train: fake amazon + real amazon, test: amazon test set\n",
      "ngram range: 1\n",
      "Multi  NB 0.652\n",
      "Ridge cls 0.6455238095238095\n",
      "SGD   cls 0.6660952380952381\n",
      "Best result in this run:  ('SGD   cls', 0.6660952380952381)\n",
      "ngram range: 1 - 2\n",
      "Multi  NB 0.6622857142857143\n",
      "Ridge cls 0.6693333333333333\n",
      "SGD   cls 0.664952380952381\n",
      "Best result in this run:  ('Ridge cls', 0.6693333333333333)\n",
      "ngram range: 1 - 3\n",
      "Multi  NB 0.6643809523809524\n",
      "Ridge cls 0.6660952380952381\n",
      "SGD   cls 0.6651428571428571\n",
      "Best result in this run:  ('Ridge cls', 0.6660952380952381)\n"
     ]
    }
   ],
   "source": [
    "# Load amazon datasets\n",
    "loader = DataLoader()\n",
    "\n",
    "path = 'data/gpt/gpt_generated_data.csv'\n",
    "gpt_data = pd.read_csv(path, sep=',')\n",
    "\n",
    "train_data = loader.load_clean_amazon(test_mode=False)\n",
    "test_data = loader.load_clean_amazon(test_mode=True)\n",
    "print(\"original pd dataframe\", len(train_data), len(test_data))\n",
    "\n",
    "\n",
    "train_data = df2dict(train_data, gpt_data, gpt_type=False, both_labels=True)\n",
    "test_data = df2dict(test_data, _, gpt_type=False, both_labels=True)\n",
    "print(\"processed data\", len(train_data['text']), len(test_data['text']))  # note the testing data should be the same\n",
    "\n",
    "print('train: fake amazon + real amazon, test: amazon test set')\n",
    "\n",
    "run_classifier((1,1), 'ngram range: 1')\n",
    "run_classifier((1,2), 'ngram range: 1 - 2')\n",
    "run_classifier((1,3), 'ngram range: 1 - 3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original pd dataframe 15750 5250\n",
      "processed data 12870 5250\n",
      "train: fake gpt + real amazon, test: amazon test set\n",
      "ngram range: 1\n",
      "Multi  NB 0.4942857142857143\n",
      "Ridge cls 0.5034285714285714\n",
      "SGD   cls 0.5055238095238095\n",
      "Best result in this run:  ('SGD   cls', 0.5055238095238095)\n",
      "ngram range: 1 - 2\n",
      "Multi  NB 0.4942857142857143\n",
      "Ridge cls 0.49676190476190474\n",
      "SGD   cls 0.49961904761904763\n",
      "Best result in this run:  ('SGD   cls', 0.49961904761904763)\n",
      "ngram range: 1 - 3\n",
      "Multi  NB 0.49447619047619046\n",
      "Ridge cls 0.4961904761904762\n",
      "SGD   cls 0.49676190476190474\n",
      "Best result in this run:  ('SGD   cls', 0.49676190476190474)\n"
     ]
    }
   ],
   "source": [
    "# Load amazon datasets\n",
    "loader = DataLoader()\n",
    "\n",
    "path = 'data/gpt/gpt_generated_data.csv'\n",
    "gpt_data = pd.read_csv(path, sep=',')\n",
    "\n",
    "train_data = loader.load_clean_amazon(test_mode=False)\n",
    "test_data = loader.load_clean_amazon(test_mode=True)\n",
    "print(\"original pd dataframe\", len(train_data), len(test_data))\n",
    "\n",
    "\n",
    "train_data = df2dict(train_data, gpt_data, ['GUIDED'], both_labels=False)\n",
    "test_data = df2dict(test_data, _, gpt_type=False, both_labels=True)\n",
    "print(\"processed data\", len(train_data['text']), len(test_data['text']))  # note the testing data should be the same\n",
    "\n",
    "print('train: fake gpt + real amazon, test: amazon test set')\n",
    "\n",
    "run_classifier((1,1), 'ngram range: 1')\n",
    "run_classifier((1,2), 'ngram range: 1 - 2')\n",
    "run_classifier((1,3), 'ngram range: 1 - 3')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original pd dataframe 15750 5250\n",
      "processed data 12871 5250\n",
      "train: fake gpt + real amazon, test: amazon test set\n",
      "ngram range: 1\n",
      "Multi  NB 0.49257142857142855\n",
      "Ridge cls 0.4980952380952381\n",
      "SGD   cls 0.49885714285714283\n",
      "Best result in this run:  ('SGD   cls', 0.49885714285714283)\n",
      "ngram range: 1 - 2\n",
      "Multi  NB 0.4942857142857143\n",
      "Ridge cls 0.4956190476190476\n",
      "SGD   cls 0.4956190476190476\n",
      "Best result in this run:  ('Ridge cls', 0.4956190476190476)\n",
      "ngram range: 1 - 3\n",
      "Multi  NB 0.49847619047619046\n",
      "Ridge cls 0.496\n",
      "SGD   cls 0.49523809523809526\n",
      "Best result in this run:  ('Multi  NB', 0.49847619047619046)\n"
     ]
    }
   ],
   "source": [
    "# Load amazon datasets\n",
    "loader = DataLoader()\n",
    "\n",
    "path = 'data/gpt/gpt_generated_data.csv'\n",
    "gpt_data = pd.read_csv(path, sep=',')\n",
    "\n",
    "train_data = loader.load_clean_amazon(test_mode=False)\n",
    "test_data = loader.load_clean_amazon(test_mode=True)\n",
    "print(\"original pd dataframe\", len(train_data), len(test_data))\n",
    "\n",
    "\n",
    "train_data = df2dict(train_data, gpt_data, ['NON-GUIDED'], both_labels=False)\n",
    "test_data = df2dict(test_data, _, gpt_type=False, both_labels=True)\n",
    "print(\"processed data\", len(train_data['text']), len(test_data['text']))  # note the testing data should be the same\n",
    "\n",
    "print('train: fake gpt + real amazon, test: amazon test set')\n",
    "\n",
    "run_classifier((1,1), 'ngram range: 1')\n",
    "run_classifier((1,2), 'ngram range: 1 - 2')\n",
    "run_classifier((1,3), 'ngram range: 1 - 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original pd dataframe 15750 5250\n",
      "processed data 17825 5250\n",
      "train: fake gpt + real amazon, test: amazon test set\n",
      "ngram range: 1\n",
      "Multi  NB 0.5211428571428571\n",
      "Ridge cls 0.5049523809523809\n",
      "SGD   cls 0.5104761904761905\n",
      "Best result in this run:  ('Multi  NB', 0.5211428571428571)\n",
      "ngram range: 1 - 2\n",
      "Multi  NB 0.5363809523809524\n",
      "Ridge cls 0.49752380952380953\n",
      "SGD   cls 0.5009523809523809\n",
      "Best result in this run:  ('Multi  NB', 0.5363809523809524)\n",
      "ngram range: 1 - 3\n",
      "Multi  NB 0.5335238095238095\n",
      "Ridge cls 0.49847619047619046\n",
      "SGD   cls 0.5013333333333333\n",
      "Best result in this run:  ('Multi  NB', 0.5335238095238095)\n"
     ]
    }
   ],
   "source": [
    "# Load amazon datasets\n",
    "loader = DataLoader()\n",
    "\n",
    "path = 'data/gpt/gpt_generated_data.csv'\n",
    "gpt_data = pd.read_csv(path, sep=',')\n",
    "\n",
    "train_data = loader.load_clean_amazon(test_mode=False)\n",
    "test_data = loader.load_clean_amazon(test_mode=True)\n",
    "print(\"original pd dataframe\", len(train_data), len(test_data))\n",
    "\n",
    "\n",
    "train_data = df2dict(train_data, gpt_data, ['GUIDED', 'NON-GUIDED'], both_labels=False)\n",
    "test_data = df2dict(test_data, _, gpt_type=False, both_labels=True)\n",
    "print(\"processed data\", len(train_data['text']), len(test_data['text']))  # note the testing data should be the same\n",
    "\n",
    "print('train: fake gpt + real amazon, test: amazon test set')\n",
    "\n",
    "run_classifier((1,1), 'ngram range: 1')\n",
    "run_classifier((1,2), 'ngram range: 1 - 2')\n",
    "run_classifier((1,3), 'ngram range: 1 - 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "original pd dataframe 15750 5250\n",
      "processed data 20705 5250\n",
      "train: fake gpt + real amazon, test: amazon test set\n",
      "ngram range: 1\n",
      "Multi  NB 0.5459047619047619\n",
      "Ridge cls 0.6310476190476191\n",
      "SGD   cls 0.6438095238095238\n",
      "Best result in this run:  ('SGD   cls', 0.6438095238095238)\n",
      "ngram range: 1 - 2\n",
      "Multi  NB 0.5089523809523809\n",
      "Ridge cls 0.6653333333333333\n",
      "SGD   cls 0.652\n",
      "Best result in this run:  ('Ridge cls', 0.6653333333333333)\n",
      "ngram range: 1 - 3\n",
      "Multi  NB 0.5087619047619047\n",
      "Ridge cls 0.6657142857142857\n",
      "SGD   cls 0.6518095238095238\n",
      "Best result in this run:  ('Ridge cls', 0.6657142857142857)\n"
     ]
    }
   ],
   "source": [
    "# Load amazon datasets\n",
    "loader = DataLoader()\n",
    "\n",
    "path = 'data/gpt/gpt_generated_data.csv'\n",
    "gpt_data = pd.read_csv(path, sep=',')\n",
    "\n",
    "train_data = loader.load_clean_amazon(test_mode=False)\n",
    "test_data = loader.load_clean_amazon(test_mode=True)\n",
    "print(\"original pd dataframe\", len(train_data), len(test_data))\n",
    "\n",
    "\n",
    "train_data = df2dict(train_data, gpt_data, ['NON-GUIDED'], both_labels=True)\n",
    "test_data = df2dict(test_data, _, gpt_type=False, both_labels=True)\n",
    "print(\"processed data\", len(train_data['text']), len(test_data['text']))  # note the testing data should be the same\n",
    "\n",
    "print('train: fake gpt + real amazon, test: amazon test set')\n",
    "\n",
    "run_classifier((1,1), 'ngram range: 1')\n",
    "run_classifier((1,2), 'ngram range: 1 - 2')\n",
    "run_classifier((1,3), 'ngram range: 1 - 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bf0f833311fc1a2d9ca1cf8207d63bf4ae3af89d2c46669381eed313e768b9d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('SNLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
