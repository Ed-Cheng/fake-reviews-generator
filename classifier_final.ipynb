{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import DataLoader\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import copy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "# from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "def shuffle_dict(data):\n",
    "    text = list(data['text'])\n",
    "    labels = list(data['labels'])\n",
    "\n",
    "    l =list(zip(text, labels))\n",
    "\n",
    "    shuffle(l)\n",
    "    text, labels = zip(*l)\n",
    "    dict = {'text': text,\n",
    "            'labels': labels} \n",
    "\n",
    "    return dict\n",
    "#   return zip(*l)\n",
    "\n",
    "\n",
    "def finalize_amazon_test(panda_data):\n",
    "    text = []\n",
    "    labels = []\n",
    "    \n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the fake data\n",
    "        if np_data[i][1] == '__label1__':\n",
    "            text.append(np_data[i][8])\n",
    "            labels.append('__label1__')\n",
    "\n",
    "        # the real data\n",
    "        else:\n",
    "            text.append(np_data[i][8])\n",
    "            labels.append('__label2__')\n",
    "\n",
    "\n",
    "    dict_test = {'text': text,\n",
    "                'labels': labels} \n",
    "\n",
    "    return dict_test\n",
    "\n",
    "\n",
    "def finalize_amazon(panda_data):\n",
    "    text_fake = []\n",
    "    labels_fake = []\n",
    "\n",
    "    text_real = []\n",
    "    labels_real = []\n",
    "    \n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the fake data\n",
    "        if np_data[i][1] == '__label1__':\n",
    "            text_fake.append(np_data[i][8])\n",
    "            labels_fake.append('__label1__')\n",
    "\n",
    "        # the real data\n",
    "        else:\n",
    "            text_real.append(np_data[i][8])\n",
    "            labels_real.append('__label2__')\n",
    "\n",
    "\n",
    "    dict_fake = {'text': text_fake,\n",
    "                'labels': labels_fake} \n",
    "\n",
    "    dict_real = {'text': text_real,\n",
    "                'labels': labels_real} \n",
    "\n",
    "    return dict_fake, dict_real\n",
    "\n",
    "\n",
    "def finalize_gpt(panda_data):\n",
    "    text_Guide = []\n",
    "    labels_Guide = []\n",
    "\n",
    "    text_nonGuide = []\n",
    "    labels_nonGuide = []\n",
    "\n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the guided data\n",
    "        if np_data[i][2] == 'GUIDED':\n",
    "            text_Guide.append(np_data[i][1])\n",
    "            labels_Guide.append('__label1__')\n",
    "\n",
    "        # the non-guided data\n",
    "        if np_data[i][2] == 'NON-GUIDED':\n",
    "            text_nonGuide.append(np_data[i][1])\n",
    "            labels_nonGuide.append('__label1__')\n",
    "\n",
    "    dict_Guide = {'text': text_Guide,\n",
    "                'labels': labels_Guide} \n",
    "\n",
    "    dict_nonGuide = {'text': text_nonGuide,\n",
    "                'labels': labels_nonGuide} \n",
    "\n",
    "    return dict_Guide, dict_nonGuide\n",
    "\n",
    "\n",
    "def finalize_gold(panda_data):\n",
    "    text_fake = []\n",
    "    labels_fake = []\n",
    "\n",
    "    text_real = []\n",
    "    labels_real = []\n",
    "    \n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the fake data\n",
    "        if np_data[i][0] == '__label1__':\n",
    "            text_fake.append(np_data[i][-1])\n",
    "            labels_fake.append('__label1__')\n",
    "\n",
    "        # the real data\n",
    "        else:\n",
    "            text_real.append(np_data[i][-1])\n",
    "            labels_real.append('__label2__')\n",
    "\n",
    "\n",
    "    dict_fake = {'text': text_fake,\n",
    "                'labels': labels_fake} \n",
    "\n",
    "    dict_real = {'text': text_real,\n",
    "                'labels': labels_real} \n",
    "\n",
    "    return dict_fake, dict_real\n",
    "\n",
    "\n",
    "def merge_data(d1, d2):\n",
    "    merged_dic = {}\n",
    "    for key in d1.keys():\n",
    "        merged_dic[key] = d1[key] + d2[key]\n",
    "    \n",
    "    return merged_dic\n",
    "\n",
    "\n",
    "def merge_shuffle_data(data1, data2):\n",
    "    data = merge_data(data1, data2)\n",
    "    data = shuffle_dict(data)\n",
    "    print('Datasets merged and shuffled, total data: ', len(data['text']))\n",
    "\n",
    "    return data\n",
    "\n",
    "def run_classifier(n_range, info, train_data, test_data):\n",
    "    print(info)\n",
    "    best_acc = 0\n",
    "    for clf, name in (\n",
    "            (LinearSVC(), \"LinearSVC\"),\n",
    "            (MultinomialNB(), \"Multi  NB\"),\n",
    "            (RidgeClassifier(), \"Ridge cls\"),\n",
    "            (SGDClassifier(), \"SGD   cls\"),\n",
    "            # the following 3 preform quite bad\n",
    "            # (PassiveAggressiveClassifier(), \"Pass-Aggr\"),\n",
    "            # (Perceptron(), \"Perceptro\"),\n",
    "            # (KNeighborsClassifier(), \"k - N - N\"),\n",
    "            ):\n",
    "\n",
    "        text_clf = Pipeline([\n",
    "                            ('vect', CountVectorizer(ngram_range=n_range)),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', clf),\n",
    "                            ])\n",
    "\n",
    "        text_clf.fit(train_data['text'], train_data['labels'])\n",
    "\n",
    "        predicted = text_clf.predict(test_data['text'])\n",
    "        acc = np.mean(predicted == test_data['labels'])\n",
    "\n",
    "        print(name, acc)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_result = (name, acc)\n",
    "    \n",
    "    print('Best result in this run: ', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the data and convert them to dictionaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edton\\Desktop\\Work\\5.UCL\\ML Masters (21-22)\\T2_COMP0087 Statistical Natural Language Processing\\NLP Group CW\\nlp_coursework_project\\utils\\loader.py:107: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(data_path, sep='   ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon testing set 5250\n",
      "amazon fake/real 7834 7916\n",
      "gold fake/real 651 629\n",
      "gold test fake/real 149 171\n",
      "gpt Guide/nonGuide 4954 4955\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "\n",
    "# Load the 3 main datasets: gold, amazon, gpt\n",
    "path = 'data/gpt/gpt_generated_data.csv'\n",
    "gpt_data = pd.read_csv(path, sep=',')\n",
    "gold_data = loader.load_gold_txt(deceptive=False, all=True)\n",
    "train_amazon = loader.load_clean_amazon(test_mode=False)\n",
    "test_amazon = loader.load_clean_amazon(test_mode=True)\n",
    "\n",
    "# process the data into dictionary to get ready to throw into the classifier \n",
    "amazon_test = finalize_amazon_test(test_amazon)\n",
    "print(\"amazon testing set\", len(amazon_test['text']))\n",
    "\n",
    "amazon_fake, amazon_real = finalize_amazon(train_amazon)\n",
    "print(\"amazon fake/real\", len(amazon_fake['text']), len(amazon_real['text']))\n",
    "\n",
    "gold_data_num  = len(gold_data)\n",
    "gold_fake, gold_real = finalize_gold(gold_data.head(int(gold_data_num * 0.8)))\n",
    "print(\"gold fake/real\", len(gold_fake['text']), len(gold_real['text']))\n",
    "gold_fake_test, gold_real_test = finalize_gold(gold_data.tail(int(gold_data_num * 0.2)))\n",
    "print(\"gold test fake/real\", len(gold_fake_test['text']), len(gold_real_test['text']))\n",
    "\n",
    "gpt_Guide, gpt_nonGuide = finalize_gpt(gpt_data)\n",
    "print(\"gpt Guide/nonGuide\", len(gpt_Guide['text']), len(gpt_nonGuide['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run the classifier with different dataset to compare\n",
    "\n",
    "+ Train: gold--------Test: gold \n",
    "+ basic trainig\n",
    "---\n",
    "+ Train: gold--------Test: amazon \n",
    "+ different test set on trained model\n",
    "---\n",
    "+ Train: amazon-----Test: amazon \n",
    "+ basic trainig\n",
    "---\n",
    "+ Train: amazon-----Test: gold \n",
    "+ different test set on trained model\n",
    "---\n",
    "+ Train: amazon real + gpt guide----------Test: amazon \n",
    "+ Train: amazon real + gpt non-guide------Test: amazon \n",
    "+ test gpt data performance, see if gpt can replace real reviews\n",
    "---\n",
    "FINAL TEST: LABEL GPT DATA AS REAL!\n",
    "+ Train: amazon fake + gpt guide (label as real)----------Test: amazon \n",
    "---\n",
    "Added: compare with final test, see if gpt data actually blends in the data\n",
    "+ Train: gold real + amazon fake --------Test: amazon \n",
    "NOTE: Compare gpt with gold dataset is meaningless as we know a model trained by a specific dataset is only capable of classifying that specific dataset. Since gpt is trained by amazon dataset, it should only compare with amazon dataset. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  320\n",
      "Datasets merged and shuffled, total data:  1280\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.909375\n",
      "Multi  NB 0.73125\n",
      "Ridge cls 0.9\n",
      "SGD   cls 0.890625\n",
      "Best result in this run:  ('LinearSVC', 0.909375)\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.5118095238095238\n",
      "Multi  NB 0.5499047619047619\n",
      "Ridge cls 0.5110476190476191\n",
      "SGD   cls 0.5154285714285715\n",
      "Best result in this run:  ('Multi  NB', 0.5499047619047619)\n"
     ]
    }
   ],
   "source": [
    "gold_test = merge_shuffle_data(gold_fake_test, gold_real_test)\n",
    "gold_mix = merge_shuffle_data(gold_fake, gold_real)\n",
    "\n",
    "run_classifier((1,2), 'ngram: 1 - 2', gold_mix, gold_test)\n",
    "run_classifier((1,2), 'ngram: 1 - 2', gold_mix, amazon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  15750\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.6651428571428571\n",
      "Multi  NB 0.6622857142857143\n",
      "Ridge cls 0.6693333333333333\n",
      "SGD   cls 0.6643809523809524\n",
      "Best result in this run:  ('Ridge cls', 0.6693333333333333)\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.575\n",
      "Multi  NB 0.6125\n",
      "Ridge cls 0.58125\n",
      "SGD   cls 0.5875\n",
      "Best result in this run:  ('Multi  NB', 0.6125)\n"
     ]
    }
   ],
   "source": [
    "amazon_mix = merge_shuffle_data(amazon_fake, amazon_real )\n",
    "\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazon_mix, amazon_test)\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazon_mix, gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  12870\n",
      "Datasets merged and shuffled, total data:  12871\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.5001904761904762\n",
      "Multi  NB 0.4942857142857143\n",
      "Ridge cls 0.49676190476190474\n",
      "SGD   cls 0.49942857142857144\n",
      "Best result in this run:  ('LinearSVC', 0.5001904761904762)\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.4956190476190476\n",
      "Multi  NB 0.4942857142857143\n",
      "Ridge cls 0.4956190476190476\n",
      "SGD   cls 0.49523809523809526\n",
      "Best result in this run:  ('LinearSVC', 0.4956190476190476)\n"
     ]
    }
   ],
   "source": [
    "amazonReal_gptGuide = merge_shuffle_data(amazon_real, gpt_Guide)\n",
    "amazonReal_gptNonGuide = merge_shuffle_data(amazon_real, gpt_nonGuide)\n",
    "\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazonReal_gptGuide, amazon_test)\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazonReal_gptNonGuide, amazon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  5583\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.534375\n",
      "Multi  NB 0.5625\n",
      "Ridge cls 0.534375\n",
      "SGD   cls 0.534375\n",
      "Best result in this run:  ('Multi  NB', 0.5625)\n"
     ]
    }
   ],
   "source": [
    "goldReal_gptGuide = merge_shuffle_data(gold_real, gpt_Guide)\n",
    "run_classifier((1,2), 'ngram: 1 - 2', goldReal_gptGuide, gold_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  12789\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.506095238095238\n",
      "Multi  NB 0.5104761904761905\n",
      "Ridge cls 0.5070476190476191\n",
      "SGD   cls 0.5072380952380953\n",
      "Best result in this run:  ('Multi  NB', 0.5104761904761905)\n"
     ]
    }
   ],
   "source": [
    "gpt_as_real = copy.deepcopy(gpt_nonGuide)\n",
    "for i in range(len(gpt_as_real['labels'])):\n",
    "    gpt_as_real['labels'][i] = '__label2__'\n",
    "\n",
    "amazonFake_gptGuide = merge_shuffle_data(gpt_as_real, amazon_fake)\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazonFake_gptGuide, amazon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bf0f833311fc1a2d9ca1cf8207d63bf4ae3af89d2c46669381eed313e768b9d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('SNLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
