{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import DataLoader\n",
    "import datasets\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n",
    "stopwords = stopwords.words('english')\n",
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\edton\\Desktop\\Work\\5.UCL\\ML Masters (21-22)\\T2_COMP0087 Statistical Natural Language Processing\\NLP Group CW\\nlp_coursework_project\\utils\\loader.py:107: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  data = pd.read_csv(data_path, sep='   ')\n"
     ]
    }
   ],
   "source": [
    "loader = DataLoader()\n",
    "train_data = loader.load_amazon(deceptive=False, all=True, test_mode=False)\n",
    "op_data = loader.load_gold_txt(deceptive=False, all=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(txt):\n",
    "    txt = ''.join([w for w in txt if w not in string.punctuation])\n",
    "    txt = txt.lower()\n",
    "    # txt = ' '.join([w for w in txt.split() if w not in stopwords])\n",
    "\n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "analyser = SentimentIntensityAnalyzer()\n",
    "\n",
    "test = []\n",
    "label = []\n",
    "test.append(train_data['REVIEW_TEXT'][0])\n",
    "label.append(train_data['LABEL'][0])\n",
    "\n",
    "for i in range(len(op_data)):\n",
    "    tx = op_data['REVIEW_TEXT'][i]\n",
    "    vadersenti = analyser.polarity_scores(tx)\n",
    "    if abs(vadersenti['compound']) > 0.5:\n",
    "        test.append(op_data['REVIEW_TEXT'][i])\n",
    "        label.append(op_data['LABEL'][i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1406"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec = CountVectorizer().fit_transform(test)\n",
    "vecs = vec.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim = cosine_similarity(vecs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = []\n",
    "for i in range(len(label)):\n",
    "    final.append([sim[0, i], label[i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in range(5, 100, 5):\n",
    "    top = final[1:n]\n",
    "    print(sum([top[i][1] for i in range(len(top))]) / n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10 Acc,  0.6\n",
      "20 Acc,  0.65\n",
      "Acc,  0.5862068965517241\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for idx in range(0,30):\n",
    "    test = []\n",
    "    label = []\n",
    "    test.append(train_data['REVIEW_TEXT'][idx])\n",
    "    label.append(train_data['LABEL'][idx])\n",
    "\n",
    "    for i in range(len(op_data)):\n",
    "        test.append(op_data['REVIEW_TEXT'][i])\n",
    "        label.append(op_data['LABEL'][i])\n",
    "\n",
    "    vec = CountVectorizer().fit_transform(test)\n",
    "    vecs = vec.toarray()\n",
    "\n",
    "    sim = cosine_similarity(vecs)\n",
    "\n",
    "    final = []\n",
    "    for i in range(len(label)):\n",
    "        final.append([sim[0, i], label[i]])\n",
    "\n",
    "    final.sort(reverse=True)\n",
    "\n",
    "    top = [final[i][1] for i in range(4)]\n",
    "\n",
    "    decision = round(sum(top[1:])/3)\n",
    "\n",
    "    \n",
    "    if top[0] == decision:\n",
    "        correct += 1\n",
    "\n",
    "    if idx % 10 == 0 and idx>0:\n",
    "        print(idx, 'Acc, ' , correct/idx)\n",
    "\n",
    "print('Acc, ' , correct/idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Acc,  0.56\n"
     ]
    }
   ],
   "source": [
    "print('Acc, ' , correct/50)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bf0f833311fc1a2d9ca1cf8207d63bf4ae3af89d2c46669381eed313e768b9d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('SNLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
