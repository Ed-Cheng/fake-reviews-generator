{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GPT-2 Review Generation Demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- This is a self-contained notebook but we also demo the sampling of prompts from the original Amazon dataset so please upload the file from path 'data/amazon_reviews/test/amazon_reviews.txt' with the notebook to colab\n",
    "- Our best model is provided in the 'training/distilgpt-topic-ft/pytorch_model.bin', please upload this .bin model file to colab alongside this notebook to load it (place in working directory).\n",
    "- We have marked below points where the marker can enter their own inputs into the model to test it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'wget' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'id' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModelForCausalLM, AutoConfig\n",
    "import torch\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "SPECIAL_TOKENS  = { \"bos_token\": \"<|BOS|>\",\n",
    "                    \"eos_token\": \"<|EOS|>\",\n",
    "                    \"unk_token\": \"<|UNK|>\",                    \n",
    "                    \"pad_token\": \"<|PAD|>\",\n",
    "                    \"sep_token\": \"<|SEP|>\"}\n",
    "MODEL = 'distilgpt2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GPT2:\n",
    "    def __init__(self, model_path=None, full_model=False, special_tokens=None) -> None:\n",
    "        self.tokenizer = self.get_tokenizer(special_tokens)\n",
    "        self.model = self.get_model(self.tokenizer, special_tokens=special_tokens, load_model_path=model_path, full_model=full_model)\n",
    "        \n",
    "    def get_tokenizer(self, special_tokens=None):\n",
    "        tokenizer = AutoTokenizer.from_pretrained(MODEL, use_fast=True)\n",
    "\n",
    "        if special_tokens:\n",
    "            tokenizer.add_special_tokens(special_tokens)\n",
    "        return tokenizer\n",
    "    \n",
    "    def get_model(self, tokenizer, special_tokens=None, load_model_path=None, full_model=False):\n",
    "        if full_model:\n",
    "            model = AutoModelForCausalLM.from_pretrained(load_model_path)\n",
    "            model.cuda()\n",
    "            return model \n",
    "        \n",
    "        if special_tokens:\n",
    "            config = AutoConfig.from_pretrained(MODEL, \n",
    "                                                bos_token_id=tokenizer.bos_token_id,\n",
    "                                                eos_token_id=tokenizer.eos_token_id,\n",
    "                                                sep_token_id=tokenizer.sep_token_id,\n",
    "                                                pad_token_id=tokenizer.pad_token_id,\n",
    "                                                output_hidden_states=False)\n",
    "        else: \n",
    "            config = AutoConfig.from_pretrained(MODEL,                                     \n",
    "                                                pad_token_id=tokenizer.eos_token_id,\n",
    "                                                output_hidden_states=False)    \n",
    "\n",
    "        model = AutoModelForCausalLM.from_pretrained(MODEL, config=config)\n",
    "\n",
    "        if special_tokens:\n",
    "            model.resize_token_embeddings(len(tokenizer))\n",
    "\n",
    "        if load_model_path:\n",
    "            model.load_state_dict(torch.load(load_model_path))\n",
    "\n",
    "        model.to(torch.device('cuda:0'))\n",
    "        return model\n",
    "    \n",
    "    def generate_text(self, prompt, category, print_output=True, **kwargs):\n",
    "        generated_outputs = []\n",
    "        \n",
    "        # Tokenize prompt\n",
    "        tokenized_prompt = self.tokenizer.encode(prompt, return_tensors='pt').to('cuda:0')\n",
    "        \n",
    "        # Language modelling\n",
    "        output = self.model.generate(tokenized_prompt, **kwargs)\n",
    "        \n",
    "        for i, o in enumerate(output):\n",
    "            gen_txt = self.tokenizer.decode(o, skip_special_tokens=True)\n",
    "            gen_txt = gen_txt[len(category):]\n",
    "            truncated_txt = gen_txt.split('.')\n",
    "            truncated_txt = '.'.join(truncated_txt[:-1]) + '.'\n",
    "            generated_outputs.append(truncated_txt)\n",
    "            \n",
    "            if print_output:\n",
    "                print(truncated_txt + '\\n')\n",
    "                \n",
    "        return generated_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_start_amazon(df, length=5):\n",
    "    sample = df.sample(n=1)\n",
    "    title, category, text = list(sample['REVIEW_TITLE'])[0], list(sample['PRODUCT_CATEGORY'])[0], list(sample['REVIEW_TEXT'])[0]\n",
    "    sample = str(text).split(' ')\n",
    "    return ' '.join(sample[:length]), title, category, text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Please ensure the amazon_reviews.txt file stated at the top of this notebook is in the working dir**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load our test-data that we will be sampling categories and prompts from\n",
    "data = pd.read_csv('amazon_reviews.txt')\n",
    "data.loc[data['LABEL'] == '__label2__', 'LABEL'] = 0\n",
    "data.loc[data['LABEL'] == '__label1__', 'LABEL'] = 1\n",
    "data_amazon = data.get(data['LABEL'] == 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Make sure the pytorch_model.bin file is in the working directory to be loaded**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the category model\n",
    "model_path = 'pytorch_model.bin'\n",
    "model = GPT2(model_path=model_path, full_model=False, special_tokens=SPECIAL_TOKENS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the available categories\n",
    "categories = ['Apparel', 'Automotive', 'Baby', 'Beauty', 'Books', 'Camera', 'Electronics', 'Furniture', 'Grocery', 'Health & Personal Care', 'Home', 'Home Entertainment', 'Home Improvement', 'Jewelry', 'Kitchen', 'Lawn and Garden', 'Luggage', 'Musical Instruments', 'Office Products', 'Outdoors', 'PC', 'Pet Products', 'Shoes', 'Sports', 'Tools', 'Toys', 'Video DVD', 'Video Games', 'Watches', 'Wireless']\n",
    "start_words = ['A', 'After', 'All', 'Any', 'Apart', 'Arrived', 'As', 'At', 'Attended', 'Avoid', 'Awesome', 'Be', 'Beautiful', 'Before', 'Booked', 'Check', \"Didn't\", 'Despite', 'Do', \"Don't\", 'Elegant', 'Even', 'Excellent', 'First', 'Firstly', 'For', 'From', 'Generally', 'Going', 'Good', 'Got', 'Great', 'Guys', 'Had', 'Have', 'Having', 'Here', 'How', 'I', \"I'd\", \"I'll\", \"I'm\", \"I've\", 'If', 'In', 'It', \"It's\", 'Just', 'Let', 'Me', 'My', 'Nice', 'No', 'Not', 'Often', 'Ok,', 'On', 'Other', 'Our', 'Overall', 'Recently', 'Rude,', 'Seriously', 'Simply', 'Sometimes', 'The', 'They', 'This', 'Used', 'Very', 'Was', 'We', \"We've\", 'Well', 'Went', 'What', \"What's\", 'When', 'While']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Random sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = np.random.choice(start_words)\n",
    "cat = np.random.choice(categories)\n",
    "prompt = SPECIAL_TOKENS['bos_token'] + cat + SPECIAL_TOKENS['sep_token'] + prompt\n",
    "outputs = model.generate_text(prompt, cat, print_output=True, do_sample=True, max_length=200, num_beams=5, repetition_penalty=5.0, early_stopping=True, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sampling from Amazon human set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt, title, cat, original = sample_start_amazon(data_amazon, length=np.random.randint(4, 8))\n",
    "prompt = SPECIAL_TOKENS['bos_token'] + cat + SPECIAL_TOKENS['sep_token'] + prompt\n",
    "outputs = model.generate_text(prompt, cat, print_output=True, do_sample=True, max_length=70, num_beams=5, repetition_penalty=5.0, early_stopping=True, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Free input section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = 'PUT YOUR PROMPT HERE'\n",
    "cat = 'PLEASE SELECT ONLY CATEGORIES AVAILABLE IN THE CATEGORIES LIST ABOVE'\n",
    "prompt = SPECIAL_TOKENS['bos_token'] + cat + SPECIAL_TOKENS['sep_token'] + prompt\n",
    "outputs = model.generate_text(prompt, cat, print_output=True, do_sample=True, max_length=70, num_beams=5, repetition_penalty=5.0, early_stopping=True, num_return_sequences=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Review Classification demo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes:\n",
    "- This part shows the top classifier models we built. \n",
    "- The classifiers are proven functional by Classifier(Gold dataset) \n",
    "- The real-world-data performance are evaluated by Classifier(Amazon dataset) \n",
    "- The GPT-2 generated dataset is proven to be able to deceive the classifier by Classifier(Amazon real + GPT-2 generated fake)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from pathlib import Path\n",
    "from random import shuffle\n",
    "import copy\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shuffle_dict(data):\n",
    "    text = list(data['text'])\n",
    "    labels = list(data['labels'])\n",
    "\n",
    "    l =list(zip(text, labels))\n",
    "\n",
    "    shuffle(l)\n",
    "    text, labels = zip(*l)\n",
    "    dict = {'text': text,\n",
    "            'labels': labels} \n",
    "\n",
    "    return dict\n",
    "\n",
    "\n",
    "def finalize_amazon_test(panda_data):\n",
    "    text = []\n",
    "    labels = []\n",
    "    \n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the fake data\n",
    "        if np_data[i][1] == '__label1__':\n",
    "            text.append(np_data[i][8])\n",
    "            labels.append('__label1__')\n",
    "\n",
    "        # the real data\n",
    "        else:\n",
    "            text.append(np_data[i][8])\n",
    "            labels.append('__label2__')\n",
    "\n",
    "\n",
    "    dict_test = {'text': text,\n",
    "                'labels': labels} \n",
    "\n",
    "    return dict_test\n",
    "\n",
    "\n",
    "def finalize_amazon(panda_data):\n",
    "    text_fake = []\n",
    "    labels_fake = []\n",
    "\n",
    "    text_real = []\n",
    "    labels_real = []\n",
    "    \n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the fake data\n",
    "        if np_data[i][1] == '__label1__':\n",
    "            text_fake.append(np_data[i][8])\n",
    "            labels_fake.append('__label1__')\n",
    "\n",
    "        # the real data\n",
    "        else:\n",
    "            text_real.append(np_data[i][8])\n",
    "            labels_real.append('__label2__')\n",
    "\n",
    "\n",
    "    dict_fake = {'text': text_fake,\n",
    "                'labels': labels_fake} \n",
    "\n",
    "    dict_real = {'text': text_real,\n",
    "                'labels': labels_real} \n",
    "\n",
    "    return dict_fake, dict_real\n",
    "\n",
    "\n",
    "def finalize_gpt(panda_data):\n",
    "    text_Guide = []\n",
    "    labels_Guide = []\n",
    "\n",
    "    text_nonGuide = []\n",
    "    labels_nonGuide = []\n",
    "\n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the guided data\n",
    "        if np_data[i][2] == 'GUIDED':\n",
    "            text_Guide.append(np_data[i][1])\n",
    "            labels_Guide.append('__label1__')\n",
    "\n",
    "        # the non-guided data\n",
    "        if np_data[i][2] == 'NON-GUIDED':\n",
    "            text_nonGuide.append(np_data[i][1])\n",
    "            labels_nonGuide.append('__label1__')\n",
    "\n",
    "    dict_Guide = {'text': text_Guide,\n",
    "                'labels': labels_Guide} \n",
    "\n",
    "    dict_nonGuide = {'text': text_nonGuide,\n",
    "                'labels': labels_nonGuide} \n",
    "\n",
    "    return dict_Guide, dict_nonGuide\n",
    "\n",
    "\n",
    "def finalize_gold(panda_data):\n",
    "    text_fake = []\n",
    "    labels_fake = []\n",
    "\n",
    "    text_real = []\n",
    "    labels_real = []\n",
    "    \n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        # the fake data\n",
    "        if np_data[i][0] == '__label1__':\n",
    "            text_fake.append(np_data[i][-1])\n",
    "            labels_fake.append('__label1__')\n",
    "\n",
    "        # the real data\n",
    "        else:\n",
    "            text_real.append(np_data[i][-1])\n",
    "            labels_real.append('__label2__')\n",
    "\n",
    "\n",
    "    dict_fake = {'text': text_fake,\n",
    "                'labels': labels_fake} \n",
    "\n",
    "    dict_real = {'text': text_real,\n",
    "                'labels': labels_real} \n",
    "\n",
    "    return dict_fake, dict_real\n",
    "\n",
    "\n",
    "def merge_data(d1, d2):\n",
    "    merged_dic = {}\n",
    "    for key in d1.keys():\n",
    "        merged_dic[key] = d1[key] + d2[key]\n",
    "    \n",
    "    return merged_dic\n",
    "\n",
    "\n",
    "def merge_shuffle_data(data1, data2):\n",
    "    data = merge_data(data1, data2)\n",
    "    data = shuffle_dict(data)\n",
    "    print('Datasets merged and shuffled, total data: ', len(data['text']))\n",
    "\n",
    "    return data\n",
    "\n",
    "def run_classifier(n_range, info, train_data, test_data):\n",
    "    print(info)\n",
    "    best_acc = 0\n",
    "    for clf, name in (\n",
    "            (LinearSVC(), \"LinearSVC\"),\n",
    "            (MultinomialNB(), \"Multi  NB\"),\n",
    "            (RidgeClassifier(), \"Ridge cls\"),\n",
    "            (SGDClassifier(), \"SGD   cls\"),\n",
    "            ):\n",
    "\n",
    "        text_clf = Pipeline([\n",
    "                            ('vect', CountVectorizer(ngram_range=n_range)),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', clf),\n",
    "                            ])\n",
    "\n",
    "        text_clf.fit(train_data['text'], train_data['labels'])\n",
    "\n",
    "        predicted = text_clf.predict(test_data['text'])\n",
    "        acc = np.mean(predicted == test_data['labels'])\n",
    "\n",
    "        print(name, acc)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_result = (name, acc)\n",
    "    \n",
    "    print('Best result in this run: ', best_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the data and seperate them into real/fake reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\edton\\AppData\\Local\\Temp/ipykernel_33124/3959665492.py:3: ParserWarning: Falling back to the 'python' engine because the 'c' engine does not support regex separators (separators > 1 char and different from '\\s+' are interpreted as regex); you can avoid this warning by specifying engine='python'.\n",
      "  gold_data = pd.read_csv('opspam.txt', sep='   ')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "amazon testing set 5250\n",
      "amazon fake/real 7834 7916\n",
      "gold fake/real 651 629\n",
      "gold test fake/real 149 171\n",
      "gpt Guide/nonGuide 4954 4954\n"
     ]
    }
   ],
   "source": [
    "# Load the 3 main datasets: gold, amazon, gpt\n",
    "gpt_data = pd.read_csv('gpt_generated_data.csv', sep=',')\n",
    "gold_data = pd.read_csv('opspam.txt', sep='   ')\n",
    "train_amazon = pd.read_csv('train/amazon_reviews.txt', sep=',')\n",
    "test_amazon = pd.read_csv('test/amazon_reviews.txt', sep=',')\n",
    "\n",
    "# process the data into dictionary to get ready to throw into the classifier \n",
    "amazon_test = finalize_amazon_test(test_amazon)\n",
    "print(\"amazon testing set\", len(amazon_test['text']))\n",
    "\n",
    "amazon_fake, amazon_real = finalize_amazon(train_amazon)\n",
    "print(\"amazon fake/real\", len(amazon_fake['text']), len(amazon_real['text']))\n",
    "\n",
    "gold_data_num  = len(gold_data)\n",
    "gold_fake, gold_real = finalize_gold(gold_data.head(int(gold_data_num * 0.8)))\n",
    "print(\"gold fake/real\", len(gold_fake['text']), len(gold_real['text']))\n",
    "gold_fake_test, gold_real_test = finalize_gold(gold_data.tail(int(gold_data_num * 0.2)))\n",
    "print(\"gold test fake/real\", len(gold_fake_test['text']), len(gold_real_test['text']))\n",
    "\n",
    "gpt_Guide, gpt_nonGuide = finalize_gpt(gpt_data)\n",
    "print(\"gpt Guide/nonGuide\", len(gpt_Guide['text']), len(gpt_nonGuide['text']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier(Gold dataset) with cross-domain classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  320\n",
      "Datasets merged and shuffled, total data:  1280\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.909375\n",
      "Multi  NB 0.73125\n",
      "Ridge cls 0.9\n",
      "SGD   cls 0.896875\n",
      "Best result in this run:  ('LinearSVC', 0.909375)\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.5118095238095238\n",
      "Multi  NB 0.5499047619047619\n",
      "Ridge cls 0.5110476190476191\n",
      "SGD   cls 0.5135238095238095\n",
      "Best result in this run:  ('Multi  NB', 0.5499047619047619)\n"
     ]
    }
   ],
   "source": [
    "gold_test = merge_shuffle_data(gold_fake_test, gold_real_test)\n",
    "gold_mix = merge_shuffle_data(gold_fake, gold_real)\n",
    "\n",
    "# Classifier trained with gold dataset, tested on gold dataset\n",
    "run_classifier((1,2), 'ngram: 1 - 2', gold_mix, gold_test)\n",
    "\n",
    "# Classifier trained with gold dataset, tested on amazon dataset (this is the cross-domain classification)\n",
    "run_classifier((1,2), 'ngram: 1 - 2', gold_mix, amazon_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier(Amazon dataset) with cross-domain classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  15750\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.6651428571428571\n",
      "Multi  NB 0.6622857142857143\n",
      "Ridge cls 0.6693333333333333\n",
      "SGD   cls 0.6660952380952381\n",
      "Best result in this run:  ('Ridge cls', 0.6693333333333333)\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.575\n",
      "Multi  NB 0.6125\n",
      "Ridge cls 0.58125\n",
      "SGD   cls 0.59375\n",
      "Best result in this run:  ('Multi  NB', 0.6125)\n"
     ]
    }
   ],
   "source": [
    "amazon_mix = merge_shuffle_data(amazon_fake, amazon_real )\n",
    "\n",
    "# Classifier trained with amazon dataset, tested on amazon dataset\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazon_mix, amazon_test)\n",
    "\n",
    "# Classifier trained with ammazon dataset, tested on gold dataset (this is the cross-domain classification)\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazon_mix, gold_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classifier(Amazon real + GPT-2 generated fake) \n",
    "\n",
    "GPT-2 generated fake data includes guided and non-guided data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datasets merged and shuffled, total data:  12870\n",
      "Datasets merged and shuffled, total data:  12870\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.5001904761904762\n",
      "Multi  NB 0.4942857142857143\n",
      "Ridge cls 0.49676190476190474\n",
      "SGD   cls 0.49866666666666665\n",
      "Best result in this run:  ('LinearSVC', 0.5001904761904762)\n",
      "ngram: 1 - 2\n",
      "LinearSVC 0.4956190476190476\n",
      "Multi  NB 0.4942857142857143\n",
      "Ridge cls 0.4956190476190476\n",
      "SGD   cls 0.49523809523809526\n",
      "Best result in this run:  ('LinearSVC', 0.4956190476190476)\n"
     ]
    }
   ],
   "source": [
    "amazonReal_gptGuide = merge_shuffle_data(amazon_real, gpt_Guide)\n",
    "amazonReal_gptNonGuide = merge_shuffle_data(amazon_real, gpt_nonGuide)\n",
    "\n",
    "# Classifier trained with (amazon real + guided GPT-2 generated fake), tested on amazon dataset\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazonReal_gptGuide, amazon_test)\n",
    "\n",
    "# Classifier trained with (amazon real + no-guided GPT-2 generated fake), tested on amazon dataset\n",
    "run_classifier((1,2), 'ngram: 1 - 2', amazonReal_gptNonGuide, amazon_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "13872f827bf2face4951d508a343680c0c465a86f8c76a51d647b255bdadb53b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
