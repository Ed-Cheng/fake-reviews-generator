{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://scikit-learn.org/stable/tutorial/text_analytics/working_with_text_data.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.loader import DataLoader\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import RidgeClassifier, SGDClassifier\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier, Perceptron\n",
    "from sklearn.neighbors import KNeighborsClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def df2dict(panda_data):\n",
    "    text = []\n",
    "    labels = []\n",
    "    np_data = panda_data.to_numpy()\n",
    "\n",
    "    for i in range(len(np_data)):\n",
    "        text.append(np_data[i][8])\n",
    "        labels.append(np_data[i][1])\n",
    "\n",
    "    data_dict = {'text': text,\n",
    "                'labels': labels} \n",
    "\n",
    "    return data_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature_extraction with sklearn methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_classifier(n_range, info):\n",
    "    print(info)\n",
    "    best_acc = 0\n",
    "    for clf, name in (\n",
    "            (LinearSVC(), \"LinearSVC\"),\n",
    "            (MultinomialNB(), \"Multi  NB\"),\n",
    "            (RidgeClassifier(), \"Ridge cls\"),\n",
    "            (SGDClassifier(), \"SGD   cls\"),\n",
    "            # the following 3 preform quite bad\n",
    "            # (PassiveAggressiveClassifier(), \"Pass-Aggr\"),\n",
    "            # (Perceptron(), \"Perceptro\"),\n",
    "            # (KNeighborsClassifier(), \"k - N - N\"),\n",
    "            ):\n",
    "\n",
    "        text_clf = Pipeline([\n",
    "                            ('vect', CountVectorizer(ngram_range=n_range)),\n",
    "                            ('tfidf', TfidfTransformer()),\n",
    "                            ('clf', clf),\n",
    "                            ])\n",
    "\n",
    "        text_clf.fit(train_data['text'], train_data['labels'])\n",
    "\n",
    "        predicted = text_clf.predict(test_data['text'])\n",
    "        acc = np.mean(predicted == test_data['labels'])\n",
    "\n",
    "        print(name, acc)\n",
    "\n",
    "        if acc > best_acc:\n",
    "            best_acc = acc\n",
    "            best_result = (name, acc)\n",
    "    \n",
    "    print('Best result in this run: ', best_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram range: 1\n",
      "LinearSVC 0.6394285714285715\n",
      "Multi  NB 0.6573333333333333\n",
      "Ridge cls 0.6508571428571429\n",
      "SGD   cls 0.6676190476190477\n",
      "Best result in this run:  ('SGD   cls', 0.6676190476190477)\n",
      "ngram range: 1 - 2\n",
      "LinearSVC 0.668\n",
      "Multi  NB 0.6662857142857143\n",
      "Ridge cls 0.6716190476190477\n",
      "SGD   cls 0.6687619047619048\n",
      "Best result in this run:  ('Ridge cls', 0.6716190476190477)\n",
      "ngram range: 1 - 3\n",
      "LinearSVC 0.6693333333333333\n",
      "Multi  NB 0.6697142857142857\n",
      "Ridge cls 0.6668571428571428\n",
      "SGD   cls 0.6657142857142857\n",
      "Best result in this run:  ('Multi  NB', 0.6697142857142857)\n",
      "ngram range: 2\n",
      "LinearSVC 0.6377142857142857\n",
      "Multi  NB 0.6518095238095238\n",
      "Ridge cls 0.6407619047619048\n",
      "SGD   cls 0.6426666666666667\n",
      "Best result in this run:  ('Multi  NB', 0.6518095238095238)\n",
      "ngram range: 2 - 3\n",
      "LinearSVC 0.6426666666666667\n",
      "Multi  NB 0.6558095238095238\n",
      "Ridge cls 0.6443809523809524\n",
      "SGD   cls 0.6449523809523809\n",
      "Best result in this run:  ('Multi  NB', 0.6558095238095238)\n"
     ]
    }
   ],
   "source": [
    "# Load amazon datasets\n",
    "# Amazon: ['DOC_ID', 'LABEL', 'RATING', 'VERIFIED_PURCHASE', 'PRODUCT_CATEGORY',\n",
    "# 'PRODUCT_ID', 'PRODUCT_TITLE', 'REVIEW_TITLE', 'REVIEW_TEXT']\n",
    "loader = DataLoader()\n",
    "\n",
    "#################### Choose which dataset to use ####################\n",
    "train_data = loader.load_amazon(deceptive=False, all=True, test_mode=False)\n",
    "test_data = loader.load_amazon(deceptive=False, all=True, test_mode=True)\n",
    "\n",
    "# train_data = loader.load_clean_amazon(test_mode=False)\n",
    "# test_data = loader.load_clean_amazon(test_mode=True)\n",
    "#################### Choose which dataset to use ####################\n",
    "\n",
    "\n",
    "train_data = df2dict(train_data)\n",
    "test_data = df2dict(test_data)\n",
    "\n",
    "run_classifier((1,1), 'ngram range: 1')\n",
    "run_classifier((1,2), 'ngram range: 1 - 2')\n",
    "run_classifier((1,3), 'ngram range: 1 - 3')\n",
    "run_classifier((2,2), 'ngram range: 2')\n",
    "run_classifier((2,3), 'ngram range: 2 - 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ngram range: 1\n",
      "LinearSVC 0.6394285714285715\n",
      "Multi  NB 0.6573333333333333\n",
      "Ridge cls 0.6508571428571429\n",
      "SGD   cls 0.663047619047619\n",
      "Best result in this run:  ('SGD   cls', 0.663047619047619)\n",
      "ngram range: 1 - 2\n",
      "LinearSVC 0.668\n",
      "Multi  NB 0.6662857142857143\n",
      "Ridge cls 0.6716190476190477\n",
      "SGD   cls 0.6685714285714286\n",
      "Best result in this run:  ('Ridge cls', 0.6716190476190477)\n",
      "ngram range: 1 - 3\n",
      "LinearSVC 0.6693333333333333\n",
      "Multi  NB 0.6697142857142857\n",
      "Ridge cls 0.6668571428571428\n",
      "SGD   cls 0.664952380952381\n",
      "Best result in this run:  ('Multi  NB', 0.6697142857142857)\n",
      "ngram range: 2\n",
      "LinearSVC 0.6377142857142857\n",
      "Multi  NB 0.6518095238095238\n",
      "Ridge cls 0.6407619047619048\n",
      "SGD   cls 0.6424761904761904\n",
      "Best result in this run:  ('Multi  NB', 0.6518095238095238)\n",
      "ngram range: 2 - 3\n",
      "LinearSVC 0.6426666666666667\n",
      "Multi  NB 0.6558095238095238\n",
      "Ridge cls 0.6443809523809524\n",
      "SGD   cls 0.6434285714285715\n",
      "Best result in this run:  ('Multi  NB', 0.6558095238095238)\n"
     ]
    }
   ],
   "source": [
    "# Load amazon datasets\n",
    "# Amazon: ['DOC_ID', 'LABEL', 'RATING', 'VERIFIED_PURCHASE', 'PRODUCT_CATEGORY',\n",
    "# 'PRODUCT_ID', 'PRODUCT_TITLE', 'REVIEW_TITLE', 'REVIEW_TEXT']\n",
    "loader = DataLoader()\n",
    "\n",
    "#################### Choose which dataset to use ####################\n",
    "# train_data = loader.load_amazon(deceptive=False, all=True, test_mode=False)\n",
    "# test_data = loader.load_amazon(deceptive=False, all=True, test_mode=True)\n",
    "\n",
    "train_data = loader.load_clean_amazon(test_mode=False)\n",
    "test_data = loader.load_clean_amazon(test_mode=True)\n",
    "#################### Choose which dataset to use ####################\n",
    "\n",
    "\n",
    "train_data = df2dict(train_data)\n",
    "test_data = df2dict(test_data)\n",
    "\n",
    "run_classifier((1,1), 'ngram range: 1')\n",
    "run_classifier((1,2), 'ngram range: 1 - 2')\n",
    "run_classifier((1,3), 'ngram range: 1 - 3')\n",
    "run_classifier((2,2), 'ngram range: 2')\n",
    "run_classifier((2,3), 'ngram range: 2 - 3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1, loss = 0.67614572\n",
      "Iteration 2, loss = 0.48562705\n",
      "Iteration 3, loss = 0.26432652\n",
      "Iteration 4, loss = 0.12981548\n",
      "Iteration 5, loss = 0.06988418\n",
      "Iteration 6, loss = 0.04317081\n",
      "Iteration 7, loss = 0.02999616\n",
      "Iteration 8, loss = 0.02272141\n",
      "Iteration 9, loss = 0.01835493\n",
      "Iteration 10, loss = 0.01550927\n",
      "Iteration 11, loss = 0.01357627\n",
      "Iteration 12, loss = 0.01219310\n",
      "Iteration 13, loss = 0.01117648\n",
      "Iteration 14, loss = 0.01040037\n",
      "Iteration 15, loss = 0.00979227\n",
      "Iteration 16, loss = 0.00930762\n",
      "Iteration 17, loss = 0.00890958\n",
      "Iteration 18, loss = 0.00857572\n",
      "Iteration 19, loss = 0.00829250\n",
      "Iteration 20, loss = 0.00804665\n",
      "Iteration 21, loss = 0.00783039\n",
      "Iteration 22, loss = 0.00763796\n",
      "Iteration 23, loss = 0.00746264\n",
      "Iteration 24, loss = 0.00730216\n",
      "Iteration 25, loss = 0.00715345\n",
      "Iteration 26, loss = 0.00701508\n",
      "Iteration 27, loss = 0.00688392\n",
      "Iteration 28, loss = 0.00675901\n",
      "Iteration 29, loss = 0.00664033\n",
      "Iteration 30, loss = 0.00652576\n",
      "Iteration 31, loss = 0.00641506\n",
      "Iteration 32, loss = 0.00630769\n",
      "Iteration 33, loss = 0.00620289\n",
      "Iteration 34, loss = 0.00610197\n",
      "Iteration 35, loss = 0.00600244\n",
      "Iteration 36, loss = 0.00590451\n",
      "Iteration 37, loss = 0.00580894\n",
      "Iteration 38, loss = 0.00571380\n",
      "Iteration 39, loss = 0.00562138\n",
      "Iteration 40, loss = 0.00553120\n",
      "Iteration 41, loss = 0.00544069\n",
      "Iteration 42, loss = 0.00535287\n",
      "Iteration 43, loss = 0.00526721\n",
      "Iteration 44, loss = 0.00518037\n",
      "Iteration 45, loss = 0.00509652\n",
      "Training loss did not improve more than tol=0.000100 for 10 consecutive epochs. Stopping.\n",
      "neural_network 0.6588571428571428\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "n_range = (1,2)\n",
    "clf = MLPClassifier(hidden_layer_sizes=(50,), max_iter=50, verbose=True)\n",
    "\n",
    "text_clf = Pipeline([\n",
    "                    ('vect', CountVectorizer(ngram_range=n_range)),\n",
    "                    ('tfidf', TfidfTransformer()),\n",
    "                    ('clf', clf),\n",
    "                    ])\n",
    "\n",
    "text_clf.fit(train_data['text'], train_data['labels'])\n",
    "\n",
    "predicted = text_clf.predict(test_data['text'])\n",
    "acc = np.mean(predicted == test_data['labels'])\n",
    "\n",
    "print('neural_network', acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1bf0f833311fc1a2d9ca1cf8207d63bf4ae3af89d2c46669381eed313e768b9d"
  },
  "kernelspec": {
   "display_name": "Python 3.8.12 ('SNLP')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
